# -*- coding: utf-8 -*-
"""BreastCancerPrediction.ipynb

Author: Fátima Sánchez Suárez
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10pUqE0qGVJZYFvf9GuOO__MT3Z9p7PPH
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from joblib import dump, load
from sklearn.metrics import confusion_matrix

# Load the dataset
data = pd.read_csv('/content/drive/MyDrive/Universidad/Semestre 9/Sistemas Inteligentes/B_Cancer.csv')

# Dataset visualization
data.head()

data.shape

corr = data[['Age', 'BMI', 'Glucose', 'Insulin', 'HOMA', 'Leptin', 'Adiponectin',
             'Resistin', 'MCP.1']].corr()

plt.figure(figsize=(10, 10))
sns.heatmap(corr, square=True, annot=True, cmap='viridis')

data.plot(kind="scatter", x="HOMA", y="Insulin",
          c="Classification", cmap=plt.get_cmap("jet"), colorbar=True,
          )
plt.legend()

data.plot(kind="scatter", x="HOMA", y="Glucose",
          c="Classification", cmap=plt.get_cmap("jet"), colorbar=True,
          )
plt.legend()

data.plot(kind="scatter", x="BMI", y="Adiponectin",
          c="Classification", cmap=plt.get_cmap("jet"), colorbar=True,
          )
plt.legend()

# Check for missing values
data.isnull().any().sum()

# Select data
X = data.drop(['Classification'], axis=1)
y = data['Classification']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# PCA keeping 91% of data significance with 6 variables
pca = PCA(.91)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)

print(X_train.shape)
print(X_test.shape)

# Training a Decision Tree
tree_clf = DecisionTreeClassifier(max_depth=4)
tree_clf.fit(X_train, y_train)

# Predicting with the test set
y_pred = tree_clf.predict(X_test)

# Accuracy
print('Accuracy:', accuracy_score(y_test, y_pred)*100)

names = tree_clf.classes_
print(names)

# Plot tree
plt.subplots(figsize=(20, 10))
tree.plot_tree(tree_clf, fontsize=10, class_names=['Negative', 'Positive'])
plt.show()

# Training a random forest
rnd_clf = RandomForestClassifier(n_estimators=10, max_leaf_nodes=16, n_jobs=-1, max_depth=5)
rnd_clf.fit(X_train, y_train)

# Predicting with the test set
y_pred_rf = rnd_clf.predict(X_test)

# Accuracy
print('Accuracy:', accuracy_score(y_test, y_pred_rf)*100)

# Plot single tree out of forest
estimator = rnd_clf.estimators_[5]
plt.subplots(figsize=(20, 10))
tree.plot_tree(estimator, fontsize=10, class_names=['Negative', 'Positive'])
plt.show()

# Confusion matrix decision tree
LABELS = ['Negative', 'Positive']
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(7, 5))
sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt="d")
plt.title("Confusion matrix")
plt.ylabel('True class')
plt.xlabel('Predicted class')
plt.show()

# Confusion matrix random forest
LABELS = ['Negative', 'Positive']
conf_matrix = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(7, 5))
sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt="d")
plt.title("Confusion matrix")
plt.ylabel('True class')
plt.xlabel('Predicted class')
plt.show()

# Save models
dump(tree_clf, 'tree_clf.joblib')
dump(rnd_clf, 'rnd_clf.joblib')

dump(scaler, 'scale.joblib')
dump(pca, 'pca.joblib')

# Load models for future predictions
tree_clf = load('/content/drive/MyDrive/Universidad/Semestre 9/Sistemas Inteligentes/tree_clf.joblib')
rnd_clf = load('/content/drive/MyDrive/Universidad/Semestre 9/Sistemas Inteligentes/rnd_clf.joblib')

scale = load('/content/drive/MyDrive/Universidad/Semestre 9/Sistemas Inteligentes/scale.joblib')
pca = load('/content/drive/MyDrive/Universidad/Semestre 9/Sistemas Inteligentes/pca.joblib')

# Predict example
data = [45, 23, 70, 2.707, 0.467409, 8.8071, 9.702400, 7.99585, 417.114]

# Preprocess data
data = np.array(data).reshape(1, -1)
x_pre = scale.transform(data)
x_pca = pca.transform(x_pre)

# Make prediction
print('Decision Tree: ', tree_clf.predict(x_pca))
print('Random Forest: ', rnd_clf.predict(x_pca))
